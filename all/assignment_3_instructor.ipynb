{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Assignment 3: Neural Networks and Embeddings\n",
    "In this assignment, you will apply some of the techniques you learned in class to build a performant sentiment analysis model and compare performance across approaches.\n",
    "\n",
    "This dataset comes from [Mass et. al. (2011)](https://www.aclweb.org/anthology/P11-1015.pdf) and the full version is available [here](http://ai.stanford.edu/~amaas/data/sentiment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "required = {'spacy', 'scikit-learn', 'numpy', 'pandas', 'torch', 'matplotlib'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spacy.lang.en import English\n",
    "en = English()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# this will set the device on which to train\n",
    "device = torch.device(\"cpu\")\n",
    "# if using collab, set your runtime to use GPU and use the line below\n",
    "#device = torch.device(\"cuda:0\")\n",
    "\n",
    "def simple_tokenizer(doc, model=en):\n",
    "    # a simple tokenizer for individual documents (different from above)\n",
    "    tokenized_docs = []\n",
    "    parsed = model(doc)\n",
    "    return([t.lower_ for t in parsed if (t.is_alpha)&(not t.like_url)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an embedding\n",
    "In class, we discussed several options for word embeddings.\n",
    "\n",
    "- One-hot encoding vectors\n",
    "- NMF/LDA topics at the word level\n",
    "- Pre-trained GloVe vectors from SpaCy\n",
    "\n",
    "These embeddings can compared to one another to assess similarity between words.  We did some of this in the class.  But, a lot of the interesting exploration of these embeddings comes from visualizing them in space.  \n",
    "\n",
    "In the [word2vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) paper, part of their evaluation of performance is to do some vector algebra (e.g. king-man+woman=queen).  This depends on a clear spatial relationship between word vectors.  Let's evaluate the spatial relationship by plotting some particular words.  Let's do this with GloVe and with our NMF/LDA topic model word embeddings.\n",
    "\n",
    "Tip: If you're not familiar with [matplotlib](https://matplotlib.org/), you'll likely need to look up how to [put together a scatterplot](https://pythonspot.com/matplotlib-scatterplot) and, additionally, how to [annotate it with text](https://stackoverflow.com/questions/14432557/matplotlib-scatter-plot-with-different-text-at-each-data-point).\n",
    "\n",
    "Tip \\#2: I'm putting some suggested seed words here, but try and think of your own.  Also feel free to do your own explorations.  Any particularly interesting ones I'll include in class next week.  Be creative here, exploratory data analysis with embeddings is something I don't think gets enough attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233 535 731\n"
     ]
    }
   ],
   "source": [
    "# you will need to change this to where ever the file is stored\n",
    "data_location = './data/assignment_1_reviews.pkl'\n",
    "with open(data_location, 'rb') as f:\n",
    "    all_text = pickle.load(f)\n",
    "neg, pos = all_text.values()\n",
    "# join all reviews\n",
    "all_reviews = np.array(neg+pos)\n",
    "# create binary indicator for positive review\n",
    "is_positive = np.array([0]*len(neg)+[1]*len(pos))\n",
    "# set the seed for numpy\n",
    "np.random.seed(seed=42)\n",
    "# shuffle, just for safety\n",
    "shuffled_idxs = np.random.choice(range(len(all_reviews)), size=len(all_reviews),replace=False)\n",
    "all_reviews = all_reviews[shuffled_idxs]\n",
    "is_positive = is_positive[shuffled_idxs]\n",
    "# sample random 70% for fitting model (training)\n",
    "# we'll also add a validation set, for checking the progress of the model during training\n",
    "# 30% will be simulating \"new observations\" (testing)\n",
    "pct_train = 0.7\n",
    "train_bool = np.random.random(len(all_reviews))<=pct_train\n",
    "reviews_train = all_reviews[train_bool]\n",
    "reviews_test = all_reviews[~train_bool]\n",
    "is_positive_train = is_positive[train_bool]\n",
    "is_positive_test = is_positive[~train_bool]\n",
    "# making a validation set\n",
    "pct_val = 0.3\n",
    "val_idxs = np.random.random(size=len(reviews_train))<=pct_val\n",
    "is_positive_val = is_positive_train[val_idxs]\n",
    "is_positive_val.shape\n",
    "reviews_val = reviews_train[val_idxs]\n",
    "# reconfigure train so that it doesn't include validation\n",
    "reviews_train = reviews_train[~val_idxs]\n",
    "is_positive_train = is_positive_train[~val_idxs]\n",
    "print(len(reviews_train), len(reviews_val), len(reviews_test))\n",
    "parsed_train = [simple_tokenizer(str(d)) for d in reviews_train]\n",
    "parsed_val = [simple_tokenizer(str(d)) for d in reviews_val]\n",
    "parsed_test = [simple_tokenizer(str(d)) for d in reviews_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab: 1765\n"
     ]
    }
   ],
   "source": [
    "# this formulation works if you have previously tokenized\n",
    "cv = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=0.01)\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=0.01)\n",
    "# **important** just fit on trained: prevents information from test in training \n",
    "cv_train = cv.fit_transform(parsed_train)\n",
    "tfidf_train = tfidf.fit_transform(parsed_train)\n",
    "# get out the vocab (same for tfidf)\n",
    "vocab = cv.vocabulary_\n",
    "print(\"Size of vocab:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic models\n",
    "n_components = 10\n",
    "nmf = NMF(n_components=n_components)\n",
    "nmf_vecs = nmf.fit_transform(tfidf_train)\n",
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "lda_vecs = lda.fit_transform(cv_train)\n",
    "nmf_words = nmf.components_.T\n",
    "lda_words = lda.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may need to install first\n",
    "# !python -m spacy download en_core_web_md\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E167] Unknown morphological feature: 'Person' (2313063860588076218). This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:\npython -m spacy validate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6b7ede57a5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mglove_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mglove_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0mexpected_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"heads\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"links\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.set_annotations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.assign_tag_id\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.add\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E167] Unknown morphological feature: 'Person' (2313063860588076218). This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:\npython -m spacy validate"
     ]
    }
   ],
   "source": [
    "# get vectors for vocab\n",
    "glove_vecs = np.zeros(shape=(len(vocab), 300))\n",
    "for k, v in vocab.items():\n",
    "    glove_vecs[v] = nlp(k).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just using seed words\n",
    "seeds = ['good', 'bad', 'great',\n",
    "         'actor', 'actress', 'acting',\n",
    "        'horror', 'comedy',\n",
    "        'drama', 'action']\n",
    "seed_idxs = [vocab[s] for s in seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vecs(vecs):\n",
    "    transformed = TSNE().fit_transform(vecs)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(transformed[seed_idxs,0], \n",
    "                transformed[seed_idxs,1])\n",
    "\n",
    "    for i, txt in enumerate(seeds):\n",
    "        coords = transformed[seed_idxs[i]]\n",
    "        ax.annotate(txt, (coords[0], coords[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_vecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0523ccf88a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_vecs' is not defined"
     ]
    }
   ],
   "source": [
    "plot_vecs(glove_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_vecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4f26a96dd647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmf_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_vecs' is not defined"
     ]
    }
   ],
   "source": [
    "plot_vecs(nmf_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_vecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-747dc2ad0d11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_vecs' is not defined"
     ]
    }
   ],
   "source": [
    "plot_vecs(lda_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have you learned from this exercise? How does the GloVe vector representation match what you'd expect? How about the NMF/LDA representations? Do you have any sense why this might be? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM sentiment prediction model\n",
    "During classes this week, we went through the code below for designing and training an LSTM model for predicting sentiment.  We outlined some of the parameters that can be tweaked in this design.  Try tweaking some of these parameters and assessing the results.\n",
    "\n",
    "Suggested tweaks:\n",
    "- NN models tend to perform better with more iterations through the data.  Try increasing the number of epochs of training\n",
    "- Dropout is one way to reduce overfitting in the model.  Try and tweak the dropout rate and see how it affects loss and accuracy\n",
    "- Smaller batch sizes may also be a way to avoid overfitting.  Try and tweak the batch size and assess\n",
    "- Learning rate adjusts how much the model learns from any given batch.  Increasing it might reduce training time.  Decreasing it might reduce overfitting.  Tweak it and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_index(docs, vocab):\n",
    "    # transform docs into series of indices\n",
    "    docs_idxs = []\n",
    "    for d in docs:\n",
    "        w_idxs = []\n",
    "        for w in d:\n",
    "            if w in vocab:\n",
    "                w_idxs.append(vocab[w])\n",
    "            else:\n",
    "                # unknown token = 1\n",
    "                w_idxs.append(1)\n",
    "        docs_idxs.append(w_idxs)\n",
    "    return(docs_idxs)\n",
    "\n",
    "def pad_sequence(seqs, seq_len=200):\n",
    "    # function for adding padding to ensure all seq same length\n",
    "    features = np.zeros((len(seqs), seq_len),dtype=int)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        if len(seq) != 0:\n",
    "            features[i, -len(seq):] = np.array(seq)[:seq_len]\n",
    "    return features\n",
    "\n",
    "class SentimentNet(nn.Module):\n",
    "    # sentiment classifier with single LSTM layer + Fully-connected layer, sigmoid activation and dropout\n",
    "    # adapted from https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
    "    def __init__(self,\n",
    "                 weight_matrix=None,\n",
    "                 vocab_size=1000, \n",
    "                 output_size=1,  \n",
    "                 hidden_dim=512,\n",
    "                 embedding_dim=400, \n",
    "                 n_layers=2, \n",
    "                 dropout_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        # size of the output, in this case it's one input to one output\n",
    "        self.output_size = output_size\n",
    "        # number of layers (default 2) one LSTM layer, one fully-connected layer\n",
    "        self.n_layers = n_layers\n",
    "        # dimensions of our hidden state, what is passed from one time point to the next\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # initialize the representation to pass to the LSTM\n",
    "        self.embedding, embedding_dim = self.init_embedding(\n",
    "            vocab_size, \n",
    "            embedding_dim, \n",
    "            weight_matrix)\n",
    "        # LSTM layer, where the magic happens\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=dropout_prob, batch_first=True)\n",
    "        # dropout, similar to regularization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        # sigmoid activiation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # forward pass of the network\n",
    "        batch_size = x.size(0)\n",
    "        # transform input\n",
    "        embeds = self.embedding(x)\n",
    "        # run input embedding + hidden state through model\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        # reshape\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # dropout certain pct of connections\n",
    "        out = self.dropout(lstm_out)\n",
    "        # fully connected layer\n",
    "        out = self.fc(out)\n",
    "        # activation function\n",
    "        out = self.sigmoid(out)\n",
    "        # reshape\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        # return the output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_embedding(self, vocab_size, embedding_dim, weight_matrix):\n",
    "        # initializes the embedding\n",
    "        if weight_matrix is None:\n",
    "            if vocab_size is None:\n",
    "                raise ValueError('If no weight matrix, need a vocab size')\n",
    "            # if embedding is a size, initialize trainable\n",
    "            return(nn.Embedding(vocab_size, embedding_dim),\n",
    "                   embedding_dim)\n",
    "        else:\n",
    "            # otherwise use matrix as pretrained\n",
    "            weights = torch.FloatTensor(weight_matrix)\n",
    "            return(nn.Embedding.from_pretrained(weights),\n",
    "                  weights.shape[1])\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # initializes the hidden state\n",
    "        hidden = (torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device),\n",
    "                  torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device))\n",
    "        return hidden\n",
    "    \n",
    "def train_model(model, train_loader, val_loader, model_params, training_params):\n",
    "    # utility for running the training process\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr=training_params['learning_rate'])\n",
    "    epochs = training_params['epochs']\n",
    "    batch_size = training_params['batch_size']\n",
    "    # print options\n",
    "    counter = 0\n",
    "    print_every = 5\n",
    "    clip = 5\n",
    "    valid_loss_min = np.Inf\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        h = model.init_hidden(batch_size)\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "            h = tuple([e.data for e in h])\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            model.zero_grad()\n",
    "            output, h = model(inputs, h)\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            if counter%print_every == 0:\n",
    "                val_h = model.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for inp, lab in val_loader:\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    inp, lab = inp.to(device), lab.to(device)\n",
    "                    out, val_h = model(inp, val_h)\n",
    "                    val_loss = criterion(out.squeeze(), lab.float())\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "                print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "                if np.mean(val_losses) <= valid_loss_min:\n",
    "                    torch.save(model.state_dict(), './state_dict.pt')\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                    valid_loss_min = np.mean(val_losses)\n",
    "    return(model)\n",
    "    \n",
    "def assess_accuracy(model, test_loader, model_params, training_params):\n",
    "    # utility for assessing accuracy\n",
    "    batch_size = training_params['batch_size']\n",
    "    model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "    h = model.init_hidden(batch_size)\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        h = tuple([each.data for each in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output, h = model(inputs, h)\n",
    "        # takes output, rounds to 0/1\n",
    "        pred = torch.round(output.squeeze())\n",
    "        # take the correct labels, check against preds\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # sum the number of correct\n",
    "        num_correct += np.sum(correct)\n",
    "    # calc accuracy\n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print('LSTM accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to adapt vocab, leave space for padding\n",
    "vocab = cv.vocabulary_\n",
    "vocab = dict([(v, vocab[v]+2) for v in vocab])\n",
    "vocab['_UNK'] = 1\n",
    "vocab['_PAD'] = 0\n",
    "# update the glove vecs accordingly\n",
    "glove_vecs = np.zeros(shape=(len(vocab), 300))\n",
    "for k, v in vocab.items():\n",
    "    glove_vecs[v] = nlp(k).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'weight_matrix': glove_vecs,\n",
    "               'output_size': 1,\n",
    "               'hidden_dim': 512,\n",
    "               'n_layers': 2,\n",
    "               'embedding_dim': 400,\n",
    "               'dropout_prob': 0.2}\n",
    "training_params = {'learning_rate': 0.005,\n",
    "                  'epochs': 1,\n",
    "                  'batch_size': 100}\n",
    "\n",
    "parsed_train = doc_to_index(parsed_train, vocab)\n",
    "padded_train = pad_sequence(parsed_train)\n",
    "parsed_val = doc_to_index(parsed_val, vocab)\n",
    "padded_val = pad_sequence(parsed_val)\n",
    "parsed_test = doc_to_index(parsed_test, vocab)\n",
    "padded_test = pad_sequence(parsed_test)\n",
    "# construct datasets for loading by PyTorch\n",
    "train_data = TensorDataset(torch.from_numpy(padded_train), torch.from_numpy(is_positive_train))\n",
    "val_data = TensorDataset(torch.from_numpy(padded_val), torch.from_numpy(is_positive_val))\n",
    "test_data = TensorDataset(torch.from_numpy(padded_test), torch.from_numpy(is_positive_test))\n",
    "\n",
    "# you'll need to re-create loaders for changes to batch size\n",
    "batch_size = training_params['batch_size']\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,\n",
    "                         drop_last=True) # this is to keep the size consistent\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size,\n",
    "                       drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentimentNet(**model_params)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(SentimentNet(**model_params), train_loader, val_loader, model_params, training_params)\n",
    "assess_accuracy(SentimentNet, test_loader, model_params, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'vocab_size': 300, # remember: this is the size of the word vector\n",
    "               'output_size': 1,\n",
    "               'hidden_dim': 512,\n",
    "               'n_layers': 2,\n",
    "               'embedding_dim': 400,\n",
    "               'dropout_prob': 0.20}\n",
    "training_params = {'learning_rate': 0.01,\n",
    "                  'epochs': 100,\n",
    "                  'batch_size': 10}\n",
    "batch_size = training_params['batch_size']\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,\n",
    "                         drop_last=True) # this is to keep the size consistent\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size,\n",
    "                       drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,\n",
    "                        drop_last=True)\n",
    "model = train_model(SentimentNet(**model_params), \n",
    "  train_loader, val_loader, model_params, training_params)\n",
    "assess_accuracy(SentimentNet(**model_params), test_loader, model_params, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
